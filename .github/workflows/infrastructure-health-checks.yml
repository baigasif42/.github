name: Infrastructure Health Checks

on:
  schedule:
    # Infrastructure checks every 4 hours
    - cron: '0 */4 * * *'
    # Daily comprehensive check at 2 AM UTC  
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      check_type:
        description: 'Type of infrastructure check'
        required: true
        default: 'standard'
        type: choice
        options:
        - standard
        - comprehensive
        - azure-only
        - kubernetes-only

env:
  DISCORD_WEBHOOK: https://discord.com/api/webhooks/1391803646500671588/7_zWESR3N1FtkNIu-vsAKdicx8JTjdlBYW0WPLvkr7VK3IaRRefqy2zW7eqEwoDqF5Cx

jobs:
  azure-infrastructure-health:
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type != 'kubernetes-only'
    outputs:
      status: ${{ steps.azure_check.outcome }}
      health_score: ${{ steps.azure_check.outputs.health_score }}
      summary: ${{ steps.azure_check.outputs.summary }}
      critical_issues: ${{ steps.azure_check.outputs.critical_issues }}
    steps:
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: '{"clientId":"${{ secrets.AZURE_CLIENT_ID }}","clientSecret":"${{ secrets.AZURE_CLIENT_SECRET }}","subscriptionId":"${{ secrets.AZURE_SUBSCRIPTION_ID }}","tenantId":"${{ secrets.AZURE_TENANT_ID }}"}'
          
      - name: Check Azure Infrastructure
        id: azure_check
        run: |
          echo "Starting Azure infrastructure health check..."
          
          # Initialize tracking
          total_checks=0
          failed_checks=0
          critical_issues=()
          
          # Function to check component status
          check_component() {
            local name="$1"
            local status="$2"
            local expected="$3"
            
            ((total_checks++))
            echo "Checking $name..."
            
            if [ "$status" = "$expected" ]; then
              echo "✅ $name: $status"
            else
              echo "❌ $name: $status (Expected: $expected)"
              ((failed_checks++))
              critical_issues+=("$name: $status")
            fi
          }
          
          echo "=== AKS CLUSTERS ==="
          
          # Development AKS
          dev_aks_status=$(az aks show --name rewardsy-dev-aks --resource-group rewardsy-dev-rg --query "powerState.code" -o tsv 2>/dev/null || echo "NotFound")
          check_component "Dev AKS Cluster" "$dev_aks_status" "Running"
          
          # Production AKS
          prod_aks_status=$(az aks show --name rewardsy-prod-aks --resource-group rewardsy-prod-rg --query "powerState.code" -o tsv 2>/dev/null || echo "NotFound")
          check_component "Prod AKS Cluster" "$prod_aks_status" "Running"
          
          echo "=== CONTAINER REGISTRIES ==="
          
          # Development ACR
          dev_acr_status=$(az acr show --name rewardsydevacr --query "provisioningState" -o tsv 2>/dev/null || echo "NotFound")
          check_component "Dev Container Registry" "$dev_acr_status" "Succeeded"
          
          # Production ACR
          prod_acr_status=$(az acr show --name rewardsyprodacr --query "provisioningState" -o tsv 2>/dev/null || echo "NotFound")
          check_component "Prod Container Registry" "$prod_acr_status" "Succeeded"
          
          echo "=== SERVICE BUS ==="
          
          # Development Service Bus
          dev_sb_status=$(az servicebus namespace show --name rewardsy-dev-servicebus --resource-group rewardsy-dev-rg --query "status" -o tsv 2>/dev/null || echo "NotFound")
          check_component "Dev Service Bus" "$dev_sb_status" "Active"
          
          # Production Service Bus
          prod_sb_status=$(az servicebus namespace show --name rewardsy-prod-servicebus --resource-group rewardsy-prod-rg --query "status" -o tsv 2>/dev/null || echo "NotFound")
          check_component "Prod Service Bus" "$prod_sb_status" "Active"
          
          echo "=== STORAGE ACCOUNTS ==="
          
          # Check main storage accounts
          storage_accounts=("rewardsydevstg" "rewardsyprodstg")
          for storage in "${storage_accounts[@]}"; do
            storage_status=$(az storage account show --name "$storage" --query "statusOfPrimary" -o tsv 2>/dev/null || echo "NotFound")
            check_component "Storage $storage" "$storage_status" "available"
          done
          
          # Calculate health score
          if [ $total_checks -eq 0 ]; then
            health_score=0
          else
            health_score=$(( (total_checks - failed_checks) * 100 / total_checks ))
          fi
          
          # Create summary
          summary="Health Score: ${health_score}%, Checked: $total_checks components, Issues: $failed_checks"
          
          # Format critical issues
          critical_list=""
          if [ ${#critical_issues[@]} -gt 0 ]; then
            critical_list=$(printf "%s; " "${critical_issues[@]}")
            critical_list=${critical_list%; }
          fi
          
          # Set outputs
          echo "health_score=$health_score" >> $GITHUB_OUTPUT
          echo "summary=$summary" >> $GITHUB_OUTPUT
          echo "critical_issues=$critical_list" >> $GITHUB_OUTPUT
          
          echo ""
          echo "=== AZURE HEALTH SUMMARY ==="
          echo "Health Score: $health_score%"
          echo "Components Checked: $total_checks"
          echo "Issues Found: $failed_checks"
          
          if [ ${#critical_issues[@]} -gt 0 ]; then
            echo "Critical Issues:"
            printf '  - %s\n' "${critical_issues[@]}"
            exit 1
          fi
          
          echo "All Azure infrastructure components are healthy"

  kubernetes-health:
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type != 'azure-only'
    outputs:
      status: ${{ steps.k8s_check.outcome }}
      pod_summary: ${{ steps.k8s_check.outputs.pod_summary }}
      namespace_details: ${{ steps.k8s_check.outputs.namespace_details }}
    steps:
      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'
          
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: '{"clientId":"${{ secrets.AZURE_CLIENT_ID }}","clientSecret":"${{ secrets.AZURE_CLIENT_SECRET }}","subscriptionId":"${{ secrets.AZURE_SUBSCRIPTION_ID }}","tenantId":"${{ secrets.AZURE_TENANT_ID }}"}'
          
      - name: Check Kubernetes Health
        id: k8s_check
        run: |
          echo "Starting Kubernetes health check..."
          
          # Standard namespaces including data analytics
          namespaces=("rewardsy-webapp" "rewardsy-backend" "rewardsy-merchant" "rewardsy-data" "rewardsy-admin")
          
          total_pods=0
          running_pods=0
          failed_pods=0
          namespace_status=()
          
          echo "=== PRODUCTION CLUSTER ==="
          
          # Connect to production cluster
          az aks get-credentials --resource-group rewardsy-prod-rg --name rewardsy-prod-aks --overwrite-existing
          
          if ! kubectl cluster-info --request-timeout=10s &>/dev/null; then
            echo "❌ Cannot connect to production cluster"
            exit 1
          fi
          
          echo "✅ Connected to production cluster"
          
          # Check for data analytics namespace
          all_namespaces=$(kubectl get namespaces -o json | jq -r '.items[].metadata.name' | grep "^rewardsy" || echo "")
          if echo "$all_namespaces" | grep -q "rewardsy-data-analytics"; then
            namespaces+=("rewardsy-data-analytics")
            echo "✅ Found rewardsy-data-analytics namespace"
          fi
          
          # Check each namespace
          for ns in "${namespaces[@]}"; do
            echo ""
            echo "Checking namespace: $ns"
            
            if kubectl get namespace "$ns" &>/dev/null; then
              ns_total=$(kubectl get pods -n "$ns" --no-headers 2>/dev/null | wc -l || echo 0)
              ns_running=$(kubectl get pods -n "$ns" --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l || echo 0)
              ns_failed=$(kubectl get pods -n "$ns" --no-headers 2>/dev/null | grep -c -E "(Failed|Error|CrashLoopBackOff)" || echo 0)
              
              total_pods=$((total_pods + ns_total))
              running_pods=$((running_pods + ns_running))
              failed_pods=$((failed_pods + ns_failed))
              
              echo "  Pods: $ns_running/$ns_total running, $ns_failed failed"
              namespace_status+=("$ns: $ns_running/$ns_total running")
              
            else
              echo "  ❌ Namespace not found"
              namespace_status+=("$ns: not found")
            fi
          done
          
          echo ""
          echo "=== DEVELOPMENT CLUSTER ==="
          
          # Quick check of development cluster
          az aks get-credentials --resource-group rewardsy-dev-rg --name rewardsy-dev-aks --overwrite-existing
          
          if kubectl cluster-info --request-timeout=10s &>/dev/null; then
            echo "✅ Connected to development cluster"
            
            dev_pods=0
            dev_running=0
            
            for ns in "${namespaces[@]}"; do
              if kubectl get namespace "$ns" &>/dev/null; then
                ns_total=$(kubectl get pods -n "$ns" --no-headers 2>/dev/null | wc -l || echo 0)
                ns_running=$(kubectl get pods -n "$ns" --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l || echo 0)
                dev_pods=$((dev_pods + ns_total))
                dev_running=$((dev_running + ns_running))
              fi
            done
            
            echo "  Development pods: $dev_running/$dev_pods running"
          else
            echo "⚠️ Cannot connect to development cluster"
            dev_running=0
            dev_pods=0
          fi
          
          # Create summaries
          prod_summary="Prod: $running_pods/$total_pods running"
          dev_summary="Dev: $dev_running/$dev_pods running"
          pod_summary="$prod_summary, $dev_summary"
          
          if [ $failed_pods -gt 0 ]; then
            pod_summary="$pod_summary (Failed: $failed_pods)"
          fi
          
          # Format namespace details
          namespace_details=$(printf "%s | " "${namespace_status[@]}")
          namespace_details=${namespace_details% | }
          
          # Set outputs
          echo "pod_summary=$pod_summary" >> $GITHUB_OUTPUT
          echo "namespace_details=$namespace_details" >> $GITHUB_OUTPUT
          
          echo ""
          echo "=== KUBERNETES SUMMARY ==="
          echo "Pod Summary: $pod_summary"
          echo "Namespace Details: $namespace_details"
          
          if [ $failed_pods -gt 0 ]; then
            echo "Kubernetes health check failed: $failed_pods pods have issues"
            exit 1
          fi
          
          echo "Kubernetes infrastructure is healthy"

  monitoring-check:
    runs-on: ubuntu-latest
    if: github.event.schedule == '0 2 * * *' || github.event.inputs.check_type == 'comprehensive'
    outputs:
      status: ${{ steps.monitoring_check.outcome }}
      monitoring_summary: ${{ steps.monitoring_check.outputs.monitoring_summary }}
    steps:
      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'
          
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: '{"clientId":"${{ secrets.AZURE_CLIENT_ID }}","clientSecret":"${{ secrets.AZURE_CLIENT_SECRET }}","subscriptionId":"${{ secrets.AZURE_SUBSCRIPTION_ID }}","tenantId":"${{ secrets.AZURE_TENANT_ID }}"}'
          
      - name: Check Monitoring Stack
        id: monitoring_check
        run: |
          echo "Checking monitoring stack..."
          
          monitoring_issues=0
          
          # Connect to production cluster
          az aks get-credentials --resource-group rewardsy-prod-rg --name rewardsy-prod-aks --overwrite-existing
          
          echo "=== ELK STACK ==="
          
          # Check ELK components
          elk_components=("elasticsearch" "kibana" "logstash")
          elk_healthy=0
          elk_total=0
          
          for component in "${elk_components[@]}"; do
            pods=$(kubectl get pods --all-namespaces --no-headers 2>/dev/null | grep "$component" | wc -l || echo 0)
            running=$(kubectl get pods --all-namespaces --no-headers 2>/dev/null | grep "$component" | grep -c "Running" || echo 0)
            
            elk_total=$((elk_total + pods))
            elk_healthy=$((elk_healthy + running))
            
            echo "$component: $running/$pods running"
            
            if [ $pods -gt 0 ] && [ $running -lt $pods ]; then
              ((monitoring_issues++))
            fi
          done
          
          echo ""
          echo "=== EXTERNAL ENDPOINTS ==="
          
          # Test Kibana accessibility
          kibana_url="https://app.rewardsy.one/kibana/"
          kibana_status=$(curl -s -o /dev/null -w "%{http_code}" --max-time 10 "$kibana_url" || echo "000")
          
          if [ "$kibana_status" = "200" ] || [ "$kibana_status" = "302" ]; then
            echo "✅ Kibana accessible (HTTP $kibana_status)"
          else
            echo "❌ Kibana not accessible (HTTP $kibana_status)"
            ((monitoring_issues++))
          fi
          
          # Create monitoring summary
          monitoring_summary="ELK: $elk_healthy/$elk_total healthy, Issues: $monitoring_issues"
          
          echo "monitoring_summary=$monitoring_summary" >> $GITHUB_OUTPUT
          
          echo ""
          echo "=== MONITORING SUMMARY ==="
          echo "$monitoring_summary"
          
          if [ $monitoring_issues -gt 1 ]; then
            echo "Monitoring check failed: $monitoring_issues issues detected"
            exit 1
          fi

  send-notifications:
    runs-on: ubuntu-latest
    needs: [azure-infrastructure-health, kubernetes-health, monitoring-check]
    if: always()
    steps:
      - name: Send Azure Infrastructure Notification
        if: needs.azure-infrastructure-health.result != 'skipped'
        uses: sarisia/actions-status-discord@v1
        with:
          webhook: ${{ env.DISCORD_WEBHOOK }}
          username: The Sentinel
          status: ${{ needs.azure-infrastructure-health.outputs.status }}
          description: |
            **${{ needs.azure-infrastructure-health.outputs.status == 'success' && 'Success' || 'Failure' }}: Health check status for Azure Infrastructure: ${{ needs.azure-infrastructure-health.outputs.status }}**
            
            ${{ needs.azure-infrastructure-health.outputs.status == 'failure' && '@everyone' || '' }} The infrastructure health check for Azure Infrastructure has finished with status: ${{ needs.azure-infrastructure-health.outputs.status }}.
            
            **Repository**
            ${{ github.repository }}
            
            **Ref**
            ${{ github.ref }}
            
            **Event - schedule**
            ${{ needs.azure-infrastructure-health.outputs.summary }}
            
            ${{ needs.azure-infrastructure-health.outputs.critical_issues && format('**Critical Issues**\n{0}', needs.azure-infrastructure-health.outputs.critical_issues) || '' }}
            
            **Triggered by**
            Asif Ali Baig
            
            **Workflow**
            Infrastructure Health Checks
          color: ${{ needs.azure-infrastructure-health.outputs.status == 'success' && 0x00ff00 || 0xff0000 }}

      - name: Send Kubernetes Infrastructure Notification
        if: needs.kubernetes-health.result != 'skipped'
        uses: sarisia/actions-status-discord@v1
        with:
          webhook: ${{ env.DISCORD_WEBHOOK }}
          username: The Sentinel
          status: ${{ needs.kubernetes-health.outputs.status }}
          description: |
            **${{ needs.kubernetes-health.outputs.status == 'success' && 'Success' || 'Failure' }}: Health check status for Kubernetes Infrastructure: ${{ needs.kubernetes-health.outputs.status }}**
            
            ${{ needs.kubernetes-health.outputs.status == 'failure' && '@everyone' || '' }} The health check for Kubernetes Infrastructure has finished with status: ${{ needs.kubernetes-health.outputs.status }}.
            
            **Repository**
            ${{ github.repository }}
            
            **Ref**
            ${{ github.ref }}
            
            **Event - schedule**
            Comprehensive Kubernetes pod and namespace analysis completed
            
            **Pod Status**
            ${{ needs.kubernetes-health.outputs.pod_summary }}
            
            **Namespace Details**
            ${{ needs.kubernetes-health.outputs.namespace_details }}
            
            **Triggered by**
            Asif Ali Baig
            
            **Workflow**
            Infrastructure Health Checks
          color: ${{ needs.kubernetes-health.outputs.status == 'success' && 0x00ff00 || 0xff0000 }}

      - name: Send Monitoring Stack Notification
        if: needs.monitoring-check.result != 'skipped' && needs.monitoring-check.result != ''
        uses: sarisia/actions-status-discord@v1
        with:
          webhook: ${{ env.DISCORD_WEBHOOK }}
          username: The Sentinel
          status: ${{ needs.monitoring-check.outputs.status }}
          description: |
            **${{ needs.monitoring-check.outputs.status == 'success' && 'Success' || 'Warning' }}: Health check status for Monitoring Stack: ${{ needs.monitoring-check.outputs.status }}**
            
            The health check for Monitoring Stack has finished with status: ${{ needs.monitoring-check.outputs.status }}.
            
            **Repository**
            ${{ github.repository }}
            
            **Ref**
            ${{ github.ref }}
            
            **Event - schedule**
            Daily monitoring infrastructure analysis completed
            
            **Monitoring Status**
            ${{ needs.monitoring-check.outputs.monitoring_summary }}
            
            **Triggered by**
            Asif Ali Baig
            
            **Workflow**
            Infrastructure Health Checks
          color: ${{ needs.monitoring-check.outputs.status == 'success' && 0x00ff00 || 0xffa500 }}